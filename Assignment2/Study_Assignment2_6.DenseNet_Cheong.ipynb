{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37431921",
   "metadata": {},
   "source": [
    "# 6. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8341610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fbab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e972e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 데이터셋을 다운로드한다.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(7),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # 회전\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 이동 및 왜곡\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(7),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # 회전\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # 이동 및 왜곡\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)),\n",
    "])\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋을 다운로드한다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adb3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(num_channels),  # 배치 정규화 추가\n",
    "        nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604066ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # Concatenate input and output of each block along the channels\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c52f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSSA_16\\anaconda3\\envs\\smplify_x4\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ac8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=1))  # Changed stride to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f45994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765fa231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    # Initialize weights for CNNs\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        \n",
    "class DenseNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),  # First conv layer\n",
    "            nn.BatchNorm2d(64),  # Batch normalization\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))  # Max pooling\n",
    "    \n",
    "    def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
    "                 lr=0.1, num_classes=10, dropout_rate=0.5):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1())  # Adding the first block `b1`\n",
    "        for i, num_convs in enumerate(arch):\n",
    "            self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs, growth_rate))\n",
    "            num_channels += num_convs * growth_rate\n",
    "            if i != len(arch) - 1:\n",
    "                num_channels //= 2\n",
    "                self.net.add_module(f'tran_blk{i+1}', transition_block(num_channels))\n",
    "            # Dropout layer\n",
    "            self.net.add_module(f'dropout{i+1}', nn.Dropout(dropout_rate))\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(num_classes)))\n",
    "\n",
    "    def para_init(self):\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e05aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (dense_blk1): DenseBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (tran_blk1): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): LazyConv2d(0, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (dense_blk2): DenseBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (tran_blk2): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): LazyConv2d(0, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (dropout2): Dropout(p=0.5, inplace=False)\n",
      "    (dense_blk3): DenseBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (tran_blk3): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): LazyConv2d(0, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "    )\n",
      "    (dropout3): Dropout(p=0.5, inplace=False)\n",
      "    (dense_blk4): DenseBlock(\n",
      "      (net): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): LazyConv2d(0, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropout4): Dropout(p=0.5, inplace=False)\n",
      "    (last): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (2): Flatten(start_dim=1, end_dim=-1)\n",
      "      (3): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(DenseNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4ac4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimzer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # 모델을 훈련 모드로 설정\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X) # 포워드 패스 수행\n",
    "        loss = loss_fn(pred, y) # CE 연산\n",
    "        \n",
    "        optimzer.zero_grad() # 0 으로 초기화\n",
    "        loss.backward() # 역전파하여 그래디언트 계산\n",
    "        optimzer.step() # 연산된 그래디언트를 사용해 파라미터를 업데이트\n",
    "        \n",
    "        if batch % 100 == 0: # 매 100회차 마다 다음 내용 출력\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f'loss: {loss}, [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval() # 모델을 실행 모드로 설정\n",
    "    \n",
    "    with torch.no_grad(): # 그래디언트 연산 안함\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X) # 포워드 패스 수행\n",
    "            test_loss += loss_fn(pred, y) # CE 연산\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 결과 일치하는지 확인\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}% Average Loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19e456c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(device):\n",
    "    #device = 'cuda:0' if torch.cuda.is_available() else 'cpu'   \n",
    "    #device = 'cpu'\n",
    "    print(f\"사용할 장치: {device}\")\n",
    "\n",
    "    model = DenseNet().to(device)\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t+1}\\n--------------------------------------')\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(train_dataloader, model, loss_fn, device)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e7a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 장치: cuda:0\n",
      "Epoch 1\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.5% Average Loss: 1.476431\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 70.3% Average Loss: 0.894926\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 75.1% Average Loss: 0.690411\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 77.4% Average Loss: 0.600286\n",
      "\n",
      "Epoch 5\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.7% Average Loss: 0.524975\n",
      "\n",
      "Epoch 6\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 80.1% Average Loss: 0.512616\n",
      "\n",
      "Epoch 7\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.0% Average Loss: 0.468492\n",
      "\n",
      "Epoch 8\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 83.8% Average Loss: 0.437227\n",
      "\n",
      "Epoch 9\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 85.1% Average Loss: 0.407206\n",
      "\n",
      "Epoch 10\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 85.5% Average Loss: 0.392781\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "run(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e3106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smplify_x4",
   "language": "python",
   "name": "smplify_x4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
