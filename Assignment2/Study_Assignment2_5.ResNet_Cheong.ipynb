{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37431921",
   "metadata": {},
   "source": [
    "# 5. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8341610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fbab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e972e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레이닝 데이터셋을 다운로드한다.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋을 다운로드한다.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a55799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):  #@save\n",
    "    \"\"\"The Residual block of ResNet models.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
    "                                   stride=strides)\n",
    "        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
    "                                       stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.bn2 = nn.BatchNorm2d(3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6d9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    # Initialize weights for CNNs\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "    \n",
    "    def block(self, num_residuals, num_channels, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(Residual(num_channels))\n",
    "        return nn.Sequential(*blk)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.net = nn.Sequential(self.b1())\n",
    "        self.net.add_module('last', nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "            nn.LazyLinear(10)))\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e05aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (net): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): LazyConv2d(0, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (last): Sequential(\n",
      "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (1): Flatten(start_dim=1, end_dim=-1)\n",
      "      (2): LazyLinear(in_features=0, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BMSSA_16\\anaconda3\\envs\\smplify_x4\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "print(ResNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4ac4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimzer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # 모델을 훈련 모드로 설정\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X) # 포워드 패스 수행\n",
    "        loss = loss_fn(pred, y) # CE 연산\n",
    "        \n",
    "        optimzer.zero_grad() # 0 으로 초기화\n",
    "        loss.backward() # 역전파하여 그래디언트 계산\n",
    "        optimzer.step() # 연산된 그래디언트를 사용해 파라미터를 업데이트\n",
    "        \n",
    "        if batch % 100 == 0: # 매 100회차 마다 다음 내용 출력\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f'loss: {loss}, [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.eval() # 모델을 실행 모드로 설정\n",
    "    \n",
    "    with torch.no_grad(): # 그래디언트 연산 안함\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X) # 포워드 패스 수행\n",
    "            test_loss += loss_fn(pred, y) # CE 연산\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # 결과 일치하는지 확인\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}% Average Loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e456c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(device):\n",
    "    #device = 'cuda:0' if torch.cuda.is_available() else 'cpu'   \n",
    "    #device = 'cpu'\n",
    "    print(f\"사용할 장치: {device}\")\n",
    "\n",
    "    model = ResNet().to(device)\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f'Epoch {t+1}\\n--------------------------------------')\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(train_dataloader, model, loss_fn, device)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e7a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용할 장치: cuda:0\n",
      "Epoch 1\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 34.8% Average Loss: 2.164437\n",
      "\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 40.6% Average Loss: 2.052777\n",
      "\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 44.1% Average Loss: 1.962613\n",
      "\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 46.4% Average Loss: 1.882167\n",
      "\n",
      "Epoch 5\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 48.2% Average Loss: 1.808484\n",
      "\n",
      "Epoch 6\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 49.5% Average Loss: 1.742005\n",
      "\n",
      "Epoch 7\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 50.7% Average Loss: 1.683370\n",
      "\n",
      "Epoch 8\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 52.1% Average Loss: 1.631605\n",
      "\n",
      "Epoch 9\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 53.6% Average Loss: 1.585644\n",
      "\n",
      "Epoch 10\n",
      "--------------------------------------\n",
      "Test Error: \n",
      " Accuracy: 54.9% Average Loss: 1.544524\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "run(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e3106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smplify_x4",
   "language": "python",
   "name": "smplify_x4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
